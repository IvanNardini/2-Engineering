{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reported-pepper",
   "metadata": {},
   "source": [
    "# Text Analysis for Women's E-Commerce Clothing Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-click",
   "metadata": {},
   "source": [
    "## Libraries and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "later-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Feature engineering\n",
    "import string\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-planning",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "processed-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = os.path.join(os.pardir, 'data', 'processed')\n",
    "RANDOM_STATE = 8\n",
    "VARIABLES_DROP = ['review_text', 'review_lower',\n",
    "       'review_nopct', 'review_nodg', 'review_word_tokens', 'review_no_sw',\n",
    "       'review_stem', 'review_lem']\n",
    "TARGET = 'recommended_ind'\n",
    "FEATURED_DIR = os.path.join(os.pardir, 'data', 'featured')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-cabinet",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "emerging-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, filename):\n",
    "    data_path = os.path.join(path, filename)\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "def get_count_words(s):\n",
    "    return len(str(s).split(\" \"))\n",
    "\n",
    "def get_count_char(s):\n",
    "    return sum(len(w) for w in str(s).split(\" \"))\n",
    "\n",
    "def get_count_sents(s):\n",
    "    return len(str(s).split(\".\"))\n",
    "\n",
    "def get_count_exc_marks(s):\n",
    "    return s.count('!')\n",
    "\n",
    "def get_count_question_marks(s):\n",
    "    return s.count('?')\n",
    "    \n",
    "def get_count_pct(s):\n",
    "    return len([w for w in s if w in '\"#$%&\\'()*+,-./:;<=>@[\\\\]^_`{|}~'])\n",
    "\n",
    "def get_count_cap(s):\n",
    "    return sum(1 for w in s if w.isupper())\n",
    "\n",
    "def get_polarity(s):\n",
    "    tb = TextBlob(s)\n",
    "    return tb.sentiment.polarity\n",
    "\n",
    "def get_subjectivity(s):\n",
    "    tb = TextBlob(s)\n",
    "    return tb.sentiment.subjectivity\n",
    "\n",
    "def get_text_features(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # word count\n",
    "    df_copy['word_count'] = df_copy['review_text'].apply(get_count_words)\n",
    "    # character count\n",
    "    df_copy['char_count'] = df_copy['review_text'].apply(get_count_char)\n",
    "    # sentence count\n",
    "    df_copy['sentence_count'] = df_copy['review_text'].apply(get_count_sents)\n",
    "    # count capitals\n",
    "    df_copy['capitals_count'] = df_copy['review_text'].apply(get_count_cap)\n",
    "    # count puncts\n",
    "    df_copy['punc_count'] = df_copy['review_text'].apply(get_count_pct)\n",
    "    df_copy['exc_marks_count'] = df_copy['review_text'].apply(get_count_exc_marks)\n",
    "    df_copy['question_marks_count'] = df_copy['review_text'].apply(get_count_question_marks)\n",
    "    # avg word len\n",
    "    df_copy['avg_word_len'] = df_copy['char_count'] / df_copy['word_count']\n",
    "    # avg sentence len\n",
    "    df_copy['avg_sentence_len'] = df_copy['word_count'] / df_copy['sentence_count']\n",
    "    # avg cap\n",
    "    df_copy['avg_cap_len']= df_copy.apply(lambda row: float(row['capitals_count'])/float(row['word_count']), axis=1)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def get_nlp_features(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # polarity\n",
    "    df_copy['polarity'] = df_copy['review_text'].apply(get_polarity)\n",
    "    # subjectivity\n",
    "    df_copy['subjectivity'] = df_copy['review_text'].apply(get_subjectivity)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def get_abt_df(df, tfidf, features, target, drop_cols):\n",
    "    df = df.copy()\n",
    "    tfidf_plain = tfidf.toarray()\n",
    "    tfidf_df = pd.DataFrame(tfidf_plain, columns=features)\n",
    "    df = df.drop(columns=drop_cols)\n",
    "    abt_df = pd.merge(df, tfidf_df, left_index=True, right_index=True)\n",
    "    cols = [col for col in abt_df if col != target] + [target]\n",
    "    abt_df = abt_df[cols]\n",
    "    return abt_df\n",
    "\n",
    "def save_data(df, path, filename):\n",
    "    data_path = os.path.join(path, filename)\n",
    "    df.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-billy",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regular-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(PROCESSED_DIR, 'train_processed.csv')\n",
    "test = load_data(PROCESSED_DIR, 'test_processed.csv')\n",
    "val = load_data(PROCESSED_DIR, 'val_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convinced-stage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>recommended_ind</th>\n",
       "      <th>review_lower</th>\n",
       "      <th>review_nopct</th>\n",
       "      <th>review_nodg</th>\n",
       "      <th>review_word_tokens</th>\n",
       "      <th>review_no_sw</th>\n",
       "      <th>review_stem</th>\n",
       "      <th>review_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867</td>\n",
       "      <td>I have been admiring this piece for awhile and...</td>\n",
       "      <td>1</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>['i', 'have', 'been', 'admiring', 'this', 'pie...</td>\n",
       "      <td>['admiring', 'piece', 'awhile', 'finally', 'de...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081</td>\n",
       "      <td>This dress looks great on me. it gives a slend...</td>\n",
       "      <td>1</td>\n",
       "      <td>this dress looks great on me. it gives a slend...</td>\n",
       "      <td>this dress looks great on me it gives a slende...</td>\n",
       "      <td>this dress looks great on me it gives a slende...</td>\n",
       "      <td>['this', 'dress', 'looks', 'great', 'on', 'me'...</td>\n",
       "      <td>['dress', 'looks', 'great', 'gives', 'slender'...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>I love this! i agree with previous post that s...</td>\n",
       "      <td>1</td>\n",
       "      <td>i love this! i agree with previous post that s...</td>\n",
       "      <td>i love this i agree with previous post that sa...</td>\n",
       "      <td>i love this i agree with previous post that sa...</td>\n",
       "      <td>['i', 'love', 'this', 'i', 'agree', 'with', 'p...</td>\n",
       "      <td>['love', 'agree', 'previous', 'post', 'say', '...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081</td>\n",
       "      <td>Not sure why this dress was once backordered? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure why this dress was once backordered? ...</td>\n",
       "      <td>not sure why this dress was once backordered i...</td>\n",
       "      <td>not sure why this dress was once backordered i...</td>\n",
       "      <td>['not', 'sure', 'why', 'this', 'dress', 'was',...</td>\n",
       "      <td>['sure', 'dress', 'backordered', 'big', 'chest...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>Unlike the other reviewers, i did not have any...</td>\n",
       "      <td>1</td>\n",
       "      <td>unlike the other reviewers, i did not have any...</td>\n",
       "      <td>unlike the other reviewers i did not have any ...</td>\n",
       "      <td>unlike the other reviewers i did not have any ...</td>\n",
       "      <td>['unlike', 'the', 'other', 'reviewers', 'i', '...</td>\n",
       "      <td>['unlike', 'reviewers', 'problem', 'sizing', '...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id                                        review_text  \\\n",
       "0          867  I have been admiring this piece for awhile and...   \n",
       "1         1081  This dress looks great on me. it gives a slend...   \n",
       "2          862  I love this! i agree with previous post that s...   \n",
       "3         1081  Not sure why this dress was once backordered? ...   \n",
       "4         1020  Unlike the other reviewers, i did not have any...   \n",
       "\n",
       "   recommended_ind                                       review_lower  \\\n",
       "0                1  i have been admiring this piece for awhile and...   \n",
       "1                1  this dress looks great on me. it gives a slend...   \n",
       "2                1  i love this! i agree with previous post that s...   \n",
       "3                0  not sure why this dress was once backordered? ...   \n",
       "4                1  unlike the other reviewers, i did not have any...   \n",
       "\n",
       "                                        review_nopct  \\\n",
       "0  i have been admiring this piece for awhile and...   \n",
       "1  this dress looks great on me it gives a slende...   \n",
       "2  i love this i agree with previous post that sa...   \n",
       "3  not sure why this dress was once backordered i...   \n",
       "4  unlike the other reviewers i did not have any ...   \n",
       "\n",
       "                                         review_nodg  \\\n",
       "0  i have been admiring this piece for awhile and...   \n",
       "1  this dress looks great on me it gives a slende...   \n",
       "2  i love this i agree with previous post that sa...   \n",
       "3  not sure why this dress was once backordered i...   \n",
       "4  unlike the other reviewers i did not have any ...   \n",
       "\n",
       "                                  review_word_tokens  \\\n",
       "0  ['i', 'have', 'been', 'admiring', 'this', 'pie...   \n",
       "1  ['this', 'dress', 'looks', 'great', 'on', 'me'...   \n",
       "2  ['i', 'love', 'this', 'i', 'agree', 'with', 'p...   \n",
       "3  ['not', 'sure', 'why', 'this', 'dress', 'was',...   \n",
       "4  ['unlike', 'the', 'other', 'reviewers', 'i', '...   \n",
       "\n",
       "                                        review_no_sw  \\\n",
       "0  ['admiring', 'piece', 'awhile', 'finally', 'de...   \n",
       "1  ['dress', 'looks', 'great', 'gives', 'slender'...   \n",
       "2  ['love', 'agree', 'previous', 'post', 'say', '...   \n",
       "3  ['sure', 'dress', 'backordered', 'big', 'chest...   \n",
       "4  ['unlike', 'reviewers', 'problem', 'sizing', '...   \n",
       "\n",
       "                                         review_stem  \\\n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...   \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...   \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...   \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...   \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...   \n",
       "\n",
       "                                          review_lem  \n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...  \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...  \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...  \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...  \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-helen",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-recommendation",
   "metadata": {},
   "source": [
    "### Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "offshore-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_feats = get_text_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sexual-scholar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>recommended_ind</th>\n",
       "      <th>review_lower</th>\n",
       "      <th>review_nopct</th>\n",
       "      <th>review_nodg</th>\n",
       "      <th>review_word_tokens</th>\n",
       "      <th>review_no_sw</th>\n",
       "      <th>review_stem</th>\n",
       "      <th>review_lem</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>avg_cap_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867</td>\n",
       "      <td>I have been admiring this piece for awhile and...</td>\n",
       "      <td>1</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>['i', 'have', 'been', 'admiring', 'this', 'pie...</td>\n",
       "      <td>['admiring', 'piece', 'awhile', 'finally', 'de...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "      <td>87</td>\n",
       "      <td>371</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.264368</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081</td>\n",
       "      <td>This dress looks great on me. it gives a slend...</td>\n",
       "      <td>1</td>\n",
       "      <td>this dress looks great on me. it gives a slend...</td>\n",
       "      <td>this dress looks great on me it gives a slende...</td>\n",
       "      <td>this dress looks great on me it gives a slende...</td>\n",
       "      <td>['this', 'dress', 'looks', 'great', 'on', 'me'...</td>\n",
       "      <td>['dress', 'looks', 'great', 'gives', 'slender'...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "      <td>22</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.318182</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>I love this! i agree with previous post that s...</td>\n",
       "      <td>1</td>\n",
       "      <td>i love this! i agree with previous post that s...</td>\n",
       "      <td>i love this i agree with previous post that sa...</td>\n",
       "      <td>i love this i agree with previous post that sa...</td>\n",
       "      <td>['i', 'love', 'this', 'i', 'agree', 'with', 'p...</td>\n",
       "      <td>['love', 'agree', 'previous', 'post', 'say', '...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "      <td>75</td>\n",
       "      <td>284</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.786667</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081</td>\n",
       "      <td>Not sure why this dress was once backordered? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure why this dress was once backordered? ...</td>\n",
       "      <td>not sure why this dress was once backordered i...</td>\n",
       "      <td>not sure why this dress was once backordered i...</td>\n",
       "      <td>['not', 'sure', 'why', 'this', 'dress', 'was',...</td>\n",
       "      <td>['sure', 'dress', 'backordered', 'big', 'chest...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "      <td>39</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>Unlike the other reviewers, i did not have any...</td>\n",
       "      <td>1</td>\n",
       "      <td>unlike the other reviewers, i did not have any...</td>\n",
       "      <td>unlike the other reviewers i did not have any ...</td>\n",
       "      <td>unlike the other reviewers i did not have any ...</td>\n",
       "      <td>['unlike', 'the', 'other', 'reviewers', 'i', '...</td>\n",
       "      <td>['unlike', 'reviewers', 'problem', 'sizing', '...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "      <td>66</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.878788</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id                                        review_text  \\\n",
       "0          867  I have been admiring this piece for awhile and...   \n",
       "1         1081  This dress looks great on me. it gives a slend...   \n",
       "2          862  I love this! i agree with previous post that s...   \n",
       "3         1081  Not sure why this dress was once backordered? ...   \n",
       "4         1020  Unlike the other reviewers, i did not have any...   \n",
       "\n",
       "   recommended_ind                                       review_lower  \\\n",
       "0                1  i have been admiring this piece for awhile and...   \n",
       "1                1  this dress looks great on me. it gives a slend...   \n",
       "2                1  i love this! i agree with previous post that s...   \n",
       "3                0  not sure why this dress was once backordered? ...   \n",
       "4                1  unlike the other reviewers, i did not have any...   \n",
       "\n",
       "                                        review_nopct  \\\n",
       "0  i have been admiring this piece for awhile and...   \n",
       "1  this dress looks great on me it gives a slende...   \n",
       "2  i love this i agree with previous post that sa...   \n",
       "3  not sure why this dress was once backordered i...   \n",
       "4  unlike the other reviewers i did not have any ...   \n",
       "\n",
       "                                         review_nodg  \\\n",
       "0  i have been admiring this piece for awhile and...   \n",
       "1  this dress looks great on me it gives a slende...   \n",
       "2  i love this i agree with previous post that sa...   \n",
       "3  not sure why this dress was once backordered i...   \n",
       "4  unlike the other reviewers i did not have any ...   \n",
       "\n",
       "                                  review_word_tokens  \\\n",
       "0  ['i', 'have', 'been', 'admiring', 'this', 'pie...   \n",
       "1  ['this', 'dress', 'looks', 'great', 'on', 'me'...   \n",
       "2  ['i', 'love', 'this', 'i', 'agree', 'with', 'p...   \n",
       "3  ['not', 'sure', 'why', 'this', 'dress', 'was',...   \n",
       "4  ['unlike', 'the', 'other', 'reviewers', 'i', '...   \n",
       "\n",
       "                                        review_no_sw  \\\n",
       "0  ['admiring', 'piece', 'awhile', 'finally', 'de...   \n",
       "1  ['dress', 'looks', 'great', 'gives', 'slender'...   \n",
       "2  ['love', 'agree', 'previous', 'post', 'say', '...   \n",
       "3  ['sure', 'dress', 'backordered', 'big', 'chest...   \n",
       "4  ['unlike', 'reviewers', 'problem', 'sizing', '...   \n",
       "\n",
       "                                         review_stem  \\\n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...   \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...   \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...   \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...   \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...   \n",
       "\n",
       "                                          review_lem  word_count  char_count  \\\n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...          87         371   \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...          22          95   \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...          75         284   \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...          39         182   \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...          66         256   \n",
       "\n",
       "   sentence_count  capitals_count  punc_count  exc_marks_count  \\\n",
       "0               5               1          13                2   \n",
       "1               3               1           3                0   \n",
       "2               7               1           8                1   \n",
       "3               5               1           4                0   \n",
       "4               5               1          10                0   \n",
       "\n",
       "   question_marks_count  avg_word_len  avg_sentence_len  avg_cap_len  \n",
       "0                     0      4.264368         17.400000     0.011494  \n",
       "1                     0      4.318182          7.333333     0.045455  \n",
       "2                     0      3.786667         10.714286     0.013333  \n",
       "3                     1      4.666667          7.800000     0.025641  \n",
       "4                     2      3.878788         13.200000     0.015152  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "closed-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_feats = get_text_features(test)\n",
    "val_text_feats = get_text_features(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-brass",
   "metadata": {},
   "source": [
    "### More NLP based features \n",
    "\n",
    "**TODO: Add Part to Speech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pending-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlp_feats = get_nlp_features(train_text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "threatened-basics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>recommended_ind</th>\n",
       "      <th>review_lower</th>\n",
       "      <th>review_nopct</th>\n",
       "      <th>review_nodg</th>\n",
       "      <th>review_word_tokens</th>\n",
       "      <th>review_no_sw</th>\n",
       "      <th>review_stem</th>\n",
       "      <th>review_lem</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>avg_cap_len</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867</td>\n",
       "      <td>I have been admiring this piece for awhile and...</td>\n",
       "      <td>1</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>i have been admiring this piece for awhile and...</td>\n",
       "      <td>['i', 'have', 'been', 'admiring', 'this', 'pie...</td>\n",
       "      <td>['admiring', 'piece', 'awhile', 'finally', 'de...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "      <td>['admir', 'piec', 'awhil', 'final', 'decid', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.264368</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.463272</td>\n",
       "      <td>0.659877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081</td>\n",
       "      <td>This dress looks great on me. it gives a slend...</td>\n",
       "      <td>1</td>\n",
       "      <td>this dress looks great on me. it gives a slend...</td>\n",
       "      <td>this dress looks great on me it gives a slende...</td>\n",
       "      <td>this dress looks great on me it gives a slende...</td>\n",
       "      <td>['this', 'dress', 'looks', 'great', 'on', 'me'...</td>\n",
       "      <td>['dress', 'looks', 'great', 'gives', 'slender'...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "      <td>['dress', 'look', 'great', 'give', 'slender', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.318182</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.794444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>I love this! i agree with previous post that s...</td>\n",
       "      <td>1</td>\n",
       "      <td>i love this! i agree with previous post that s...</td>\n",
       "      <td>i love this i agree with previous post that sa...</td>\n",
       "      <td>i love this i agree with previous post that sa...</td>\n",
       "      <td>['i', 'love', 'this', 'i', 'agree', 'with', 'p...</td>\n",
       "      <td>['love', 'agree', 'previous', 'post', 'say', '...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "      <td>['love', 'agre', 'previou', 'post', 'say', 'mu...</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.786667</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.299444</td>\n",
       "      <td>0.581806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081</td>\n",
       "      <td>Not sure why this dress was once backordered? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>not sure why this dress was once backordered? ...</td>\n",
       "      <td>not sure why this dress was once backordered i...</td>\n",
       "      <td>not sure why this dress was once backordered i...</td>\n",
       "      <td>['not', 'sure', 'why', 'this', 'dress', 'was',...</td>\n",
       "      <td>['sure', 'dress', 'backordered', 'big', 'chest...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "      <td>['sure', 'dress', 'backord', 'big', 'chest', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>-0.057937</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>Unlike the other reviewers, i did not have any...</td>\n",
       "      <td>1</td>\n",
       "      <td>unlike the other reviewers, i did not have any...</td>\n",
       "      <td>unlike the other reviewers i did not have any ...</td>\n",
       "      <td>unlike the other reviewers i did not have any ...</td>\n",
       "      <td>['unlike', 'the', 'other', 'reviewers', 'i', '...</td>\n",
       "      <td>['unlike', 'reviewers', 'problem', 'sizing', '...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "      <td>['unlik', 'review', 'problem', 'size', 'fit', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.878788</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.591667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id                                        review_text  \\\n",
       "0          867  I have been admiring this piece for awhile and...   \n",
       "1         1081  This dress looks great on me. it gives a slend...   \n",
       "2          862  I love this! i agree with previous post that s...   \n",
       "3         1081  Not sure why this dress was once backordered? ...   \n",
       "4         1020  Unlike the other reviewers, i did not have any...   \n",
       "\n",
       "   recommended_ind                                       review_lower  \\\n",
       "0                1  i have been admiring this piece for awhile and...   \n",
       "1                1  this dress looks great on me. it gives a slend...   \n",
       "2                1  i love this! i agree with previous post that s...   \n",
       "3                0  not sure why this dress was once backordered? ...   \n",
       "4                1  unlike the other reviewers, i did not have any...   \n",
       "\n",
       "                                        review_nopct  \\\n",
       "0  i have been admiring this piece for awhile and...   \n",
       "1  this dress looks great on me it gives a slende...   \n",
       "2  i love this i agree with previous post that sa...   \n",
       "3  not sure why this dress was once backordered i...   \n",
       "4  unlike the other reviewers i did not have any ...   \n",
       "\n",
       "                                         review_nodg  \\\n",
       "0  i have been admiring this piece for awhile and...   \n",
       "1  this dress looks great on me it gives a slende...   \n",
       "2  i love this i agree with previous post that sa...   \n",
       "3  not sure why this dress was once backordered i...   \n",
       "4  unlike the other reviewers i did not have any ...   \n",
       "\n",
       "                                  review_word_tokens  \\\n",
       "0  ['i', 'have', 'been', 'admiring', 'this', 'pie...   \n",
       "1  ['this', 'dress', 'looks', 'great', 'on', 'me'...   \n",
       "2  ['i', 'love', 'this', 'i', 'agree', 'with', 'p...   \n",
       "3  ['not', 'sure', 'why', 'this', 'dress', 'was',...   \n",
       "4  ['unlike', 'the', 'other', 'reviewers', 'i', '...   \n",
       "\n",
       "                                        review_no_sw  \\\n",
       "0  ['admiring', 'piece', 'awhile', 'finally', 'de...   \n",
       "1  ['dress', 'looks', 'great', 'gives', 'slender'...   \n",
       "2  ['love', 'agree', 'previous', 'post', 'say', '...   \n",
       "3  ['sure', 'dress', 'backordered', 'big', 'chest...   \n",
       "4  ['unlike', 'reviewers', 'problem', 'sizing', '...   \n",
       "\n",
       "                                         review_stem  \\\n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...   \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...   \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...   \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...   \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...   \n",
       "\n",
       "                                          review_lem  ...  sentence_count  \\\n",
       "0  ['admir', 'piec', 'awhil', 'final', 'decid', '...  ...               5   \n",
       "1  ['dress', 'look', 'great', 'give', 'slender', ...  ...               3   \n",
       "2  ['love', 'agre', 'previou', 'post', 'say', 'mu...  ...               7   \n",
       "3  ['sure', 'dress', 'backord', 'big', 'chest', '...  ...               5   \n",
       "4  ['unlik', 'review', 'problem', 'size', 'fit', ...  ...               5   \n",
       "\n",
       "   capitals_count  punc_count  exc_marks_count  question_marks_count  \\\n",
       "0               1          13                2                     0   \n",
       "1               1           3                0                     0   \n",
       "2               1           8                1                     0   \n",
       "3               1           4                0                     1   \n",
       "4               1          10                0                     2   \n",
       "\n",
       "   avg_word_len  avg_sentence_len  avg_cap_len  polarity  subjectivity  \n",
       "0      4.264368         17.400000     0.011494  0.463272      0.659877  \n",
       "1      4.318182          7.333333     0.045455  0.544444      0.794444  \n",
       "2      3.786667         10.714286     0.013333  0.299444      0.581806  \n",
       "3      4.666667          7.800000     0.025641 -0.057937      0.411111  \n",
       "4      3.878788         13.200000     0.015152  0.420833      0.591667  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nlp_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "subject-relationship",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_nlp_feats = get_nlp_features(test_text_feats)\n",
    "val_nlp_feats = get_nlp_features(val_text_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-nickel",
   "metadata": {},
   "source": [
    "### TF-IDF Feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "solved-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf_vectorizer = tf_idf_vectorizer.fit(train_nlp_feats['review_lem'])\n",
    "tf_idf_train_matrix = tf_idf_vectorizer.transform(train_nlp_feats['review_lem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crucial-colors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22248x11173 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 578756 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "clean-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test_matrix = tf_idf_vectorizer.transform(test_nlp_feats['review_lem'])\n",
    "tf_idf_val_matrix = tf_idf_vectorizer.transform(val_nlp_feats['review_lem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-income",
   "metadata": {},
   "source": [
    "### TODO: Add Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-diameter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "applied-enemy",
   "metadata": {},
   "source": [
    "### TODO: Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-africa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "discrete-underwear",
   "metadata": {},
   "source": [
    "## ABTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "awful-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = tf_idf_vectorizer.get_feature_names()\n",
    "abt_train = get_abt_df(train_nlp_feats, tf_idf_train_matrix, FEATURES, TARGET, VARIABLES_DROP)\n",
    "abt_test = get_abt_df(test_nlp_feats, tf_idf_test_matrix, FEATURES, TARGET, VARIABLES_DROP)\n",
    "abt_val = get_abt_df(val_nlp_feats, tf_idf_val_matrix, FEATURES, TARGET, VARIABLES_DROP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "macro-letter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>...</th>\n",
       "      <th>ziphoodi</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuma</th>\n",
       "      <th>recommended_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867</td>\n",
       "      <td>87</td>\n",
       "      <td>371</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.264368</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081</td>\n",
       "      <td>22</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.318182</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862</td>\n",
       "      <td>75</td>\n",
       "      <td>284</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.786667</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081</td>\n",
       "      <td>39</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>66</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.878788</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  word_count  char_count  sentence_count  capitals_count  \\\n",
       "0          867          87         371               5               1   \n",
       "1         1081          22          95               3               1   \n",
       "2          862          75         284               7               1   \n",
       "3         1081          39         182               5               1   \n",
       "4         1020          66         256               5               1   \n",
       "\n",
       "   punc_count  exc_marks_count  question_marks_count  avg_word_len  \\\n",
       "0          13                2                     0      4.264368   \n",
       "1           3                0                     0      4.318182   \n",
       "2           8                1                     0      3.786667   \n",
       "3           4                0                     1      4.666667   \n",
       "4          10                0                     2      3.878788   \n",
       "\n",
       "   avg_sentence_len  ...  ziphoodi  ziploc  zipper  zipperi  zombi  zone  \\\n",
       "0         17.400000  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "1          7.333333  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "2         10.714286  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "3          7.800000  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "4         13.200000  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "\n",
       "   zooland  zoom  zuma  recommended_ind  \n",
       "0      0.0   0.0   0.0                1  \n",
       "1      0.0   0.0   0.0                1  \n",
       "2      0.0   0.0   0.0                1  \n",
       "3      0.0   0.0   0.0                0  \n",
       "4      0.0   0.0   0.0                1  \n",
       "\n",
       "[5 rows x 11187 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abt_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stock-venice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>...</th>\n",
       "      <th>ziphoodi</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuma</th>\n",
       "      <th>recommended_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>927</td>\n",
       "      <td>38</td>\n",
       "      <td>152</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>820</td>\n",
       "      <td>93</td>\n",
       "      <td>408</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.387097</td>\n",
       "      <td>11.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>936</td>\n",
       "      <td>96</td>\n",
       "      <td>407</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.239583</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>862</td>\n",
       "      <td>27</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1061</td>\n",
       "      <td>31</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.741935</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  word_count  char_count  sentence_count  capitals_count  \\\n",
       "0          927          38         152               9               1   \n",
       "1          820          93         408               8               1   \n",
       "2          936          96         407               6               1   \n",
       "3          862          27         153               1               1   \n",
       "4         1061          31         116               5               1   \n",
       "\n",
       "   punc_count  exc_marks_count  question_marks_count  avg_word_len  \\\n",
       "0           9                0                     0      4.000000   \n",
       "1          15                1                     0      4.387097   \n",
       "2          15                0                     0      4.239583   \n",
       "3           2                0                     0      5.666667   \n",
       "4           5                0                     0      3.741935   \n",
       "\n",
       "   avg_sentence_len  ...  ziphoodi  ziploc  zipper  zipperi  zombi  zone  \\\n",
       "0          4.222222  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "1         11.625000  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "2         16.000000  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "3         27.000000  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "4          6.200000  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "\n",
       "   zooland  zoom  zuma  recommended_ind  \n",
       "0      0.0   0.0   0.0                0  \n",
       "1      0.0   0.0   0.0                0  \n",
       "2      0.0   0.0   0.0                0  \n",
       "3      0.0   0.0   0.0                1  \n",
       "4      0.0   0.0   0.0                0  \n",
       "\n",
       "[5 rows x 11187 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abt_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "frank-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>capitals_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>exc_marks_count</th>\n",
       "      <th>question_marks_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>avg_sentence_len</th>\n",
       "      <th>...</th>\n",
       "      <th>ziphoodi</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuma</th>\n",
       "      <th>recommended_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1066</td>\n",
       "      <td>54</td>\n",
       "      <td>197</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.648148</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1055</td>\n",
       "      <td>63</td>\n",
       "      <td>260</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.126984</td>\n",
       "      <td>10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1066</td>\n",
       "      <td>60</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>863</td>\n",
       "      <td>67</td>\n",
       "      <td>269</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.014925</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872</td>\n",
       "      <td>48</td>\n",
       "      <td>197</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.104167</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing_id  word_count  char_count  sentence_count  capitals_count  \\\n",
       "0         1066          54         197               6               1   \n",
       "1         1055          63         260               6               1   \n",
       "2         1066          60         272               4               1   \n",
       "3          863          67         269               5               1   \n",
       "4          872          48         197               4               1   \n",
       "\n",
       "   punc_count  exc_marks_count  question_marks_count  avg_word_len  \\\n",
       "0          16                0                     0      3.648148   \n",
       "1          10                1                     0      4.126984   \n",
       "2           8                1                     0      4.533333   \n",
       "3          12                1                     0      4.014925   \n",
       "4           8                1                     0      4.104167   \n",
       "\n",
       "   avg_sentence_len  ...  ziphoodi  ziploc  zipper  zipperi  zombi  zone  \\\n",
       "0               9.0  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "1              10.5  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "2              15.0  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "3              13.4  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "4              12.0  ...       0.0     0.0     0.0      0.0    0.0   0.0   \n",
       "\n",
       "   zooland  zoom  zuma  recommended_ind  \n",
       "0      0.0   0.0   0.0                1  \n",
       "1      0.0   0.0   0.0                0  \n",
       "2      0.0   0.0   0.0                0  \n",
       "3      0.0   0.0   0.0                1  \n",
       "4      0.0   0.0   0.0                0  \n",
       "\n",
       "[5 rows x 11187 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abt_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-sunset",
   "metadata": {},
   "source": [
    "## Store Featured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interior-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "abts = [abt_train, abt_test, abt_val]\n",
    "fnames = ['train_abt.csv', 'test_abt.csv', 'val_abt.csv']\n",
    "\n",
    "p = Path(FEATURED_DIR)\n",
    "if not p.exists():\n",
    "    os.mkdir(p)\n",
    "for df, fname in zip(abts, fnames):\n",
    "    save_data(df=df, path=FEATURED_DIR, filename=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-sleeping",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
